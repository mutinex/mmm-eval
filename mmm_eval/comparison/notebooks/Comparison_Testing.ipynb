{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e450d804-52ac-4c29-94a4-4c6b4e4e209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: pandas_gbq in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (0.29.2)\n",
      "Requirement already satisfied: setuptools in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (80.9.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (20.0.0)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.9.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.10.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.25.1)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0,>=3.4.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (3.34.0)\n",
      "Requirement already satisfied: packaging>=22.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2.32.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.9.0.post0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.73.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.13.0->pandas_gbq) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas>=1.1.4->pandas_gbq) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas>=1.1.4->pandas_gbq) (2025.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "!pip install pandas_gbq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_gbq as bq\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from google.oauth2 import service_account\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "from mmm_eval.comparison.load import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20df2b45-a7a9-4a8a-8bd0-358ff2109bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.comparison.load import get_datasets\n",
    "#stage = \"warchest-staging-323804\"  # \"warchest-develop\"\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/samuelmccormick/.config/gcloud/application_default_credentials.json\"\n",
    "project_id = \"mtx-dataos-datalake-prod\"\n",
    "customer_id = \"bank_australia_43\"\n",
    "dataset_name = customer_id + '_datamart'\n",
    "customer_name = customer_id.rpartition(\"_\")[0]\n",
    "data_version = \"2025-07-10T05:08:31.208146\"\n",
    "#datasets = get_datasets(project_id, dataset_name, data_version, node_filter=\"default.default.home_loans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e8b94-a221-4a7f-9c1d-652c088e6272",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "Pass the following args:\n",
    "\n",
    "- Customer slug\n",
    "- Data version\n",
    "- Holiday names\n",
    "- Pipeline link\n",
    "\n",
    "then\n",
    "\n",
    "- process all datasets and merge them together\n",
    "- call functions to construct data configs for each framework\n",
    "- transformations\n",
    "  - PyMC: maxabs scale all control columns\n",
    "  - Meridian: add dummy geo column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed1427-86f6-457b-b7eb-428abecaff33",
   "metadata": {},
   "source": [
    "## Turn into DFs for PyMC\n",
    "- Restrict to node(s) of interest\n",
    "- Convert all datasets to weekly\n",
    "- Load holidays and process them\n",
    "- Merge together into a single dataframe\n",
    "- Set up config fields based on dataset column mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d80a706-8d09-4bdc-9315-66c4ec83ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mmm_eval.comparison.utils as utils\n",
    "# from mmm_eval.comparison.load import aggregate_to_node_level, convert_df_to_weekly\n",
    "\n",
    "# sales_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"sales_snapshot\"],\n",
    "#     numerical_columns=[\"quantity\", \"value\"],\n",
    "#     downsample_method_to_daily={\"value\": utils.DownsampleMethod.UNIFORM, \"quantity\": utils.DownsampleMethod.UNIFORM},\n",
    "#     agg_method_to_weekly={\"value\": \"sum\", \"quantity\": \"sum\"},\n",
    "# )\n",
    "\n",
    "# sales = aggregate_to_node_level(\n",
    "#     sales_weekly, extra_group_cols=[], agg_mapping={\"quantity\": \"sum\", \"value\": \"sum\"}\n",
    "# )\n",
    "\n",
    "# sales_proc = sales[[\"date\", \"quantity\", \"value\"]].set_index(\"date\").rename(columns={\"value\": \"revenue\"})\n",
    "# sales_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94f689-b7c8-4b93-858c-aa8ea11b05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns = [\n",
    "#     \"impressions\",\n",
    "#     \"funnel_stage\",\n",
    "#     \"tarp\",\n",
    "#     \"fees\",\n",
    "# ]\n",
    "\n",
    "# if \"impressions\" in datasets[\"paid_media_snapshot\"].columns:\n",
    "#     datasets['paid_media_snapshot'].drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# # Convert to weekly then aggregate to node or lower level\n",
    "# paid_media_weekly = convert_df_to_weekly(\n",
    "#     datasets['paid_media_snapshot'],\n",
    "#     numerical_columns=[\"spend\"],\n",
    "#     downsample_method_to_daily={\n",
    "#         \"spend\": utils.DownsampleMethod.UNIFORM,\n",
    "#     },\n",
    "#     agg_method_to_weekly={\n",
    "#         \"spend\": \"sum\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# paid_media = aggregate_to_node_level(\n",
    "#     paid_media_weekly, extra_group_cols=[\"media_channel\", \"marketing_spend_impact\"], agg_mapping={\"spend\": \"sum\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bacc1-0712-46f0-b309-e4efbd859f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot out by spend impact\n",
    "# pivoted = paid_media.pivot(columns=[\"media_channel\", \"marketing_spend_impact\"], values=\"spend\", index=\"date\")\n",
    "# pivoted.columns = ['_'.join(col).strip() for col in pivoted.columns.values]\n",
    "# paid_media_pivoted = pivoted.fillna(0)\n",
    "# paid_media_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf59571-dd24-4c60-a6c2-16ff9cf46a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricing_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"pricing_snapshot\"],\n",
    "#     numerical_columns=[\"retail_price\"],\n",
    "#     downsample_method_to_daily={\n",
    "#         \"retail_price\": utils.DownsampleMethod.REPLICA,\n",
    "#     },\n",
    "#     agg_method_to_weekly={\n",
    "#         \"retail_price\": \"mean\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# pricing = aggregate_to_node_level(\n",
    "#     pricing_weekly, extra_group_cols=[\"company\"], agg_mapping={\"retail_price\": \"mean\"}\n",
    "# )\n",
    "# # alternative is to include competitor prices as separate cols\n",
    "# pricing = pricing[pricing[\"company\"]==\"bank_australia\"]\n",
    "# pricing = pricing[[\"date\", \"retail_price\"]].set_index(\"date\").ffill()\n",
    "# pricing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662259d4-b7e5-416e-87b5-9026faaa5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"events_snapshot\"],\n",
    "#     numerical_columns=[\"duration\",],\n",
    "#     downsample_method_to_daily=utils.DownsampleMethod.REPLICA,\n",
    "#     agg_method_to_weekly={\n",
    "#         \"duration\": \"sum\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# events = aggregate_to_node_level(\n",
    "#     events_weekly, extra_group_cols=[\"event_type\", \"event_purpose\"], agg_mapping={\"duration\": \"sum\"}\n",
    "# )\n",
    "# events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12d1a4-b348-475c-91d2-8d675a3b1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_matrix = pd.crosstab(events[\"date\"], events[\"event_purpose\"])\n",
    "# binary_matrix = binary_matrix.astype(bool).astype(int)\n",
    "# events_dense = binary_matrix.reindex(sales_proc.index, fill_value=0)\n",
    "# events_dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8b1022-b247-42c6-ba11-6870bc92c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = pd.merge(sales_proc, paid_media_pivoted, left_index=True, right_index=True)\n",
    "# merged = pd.merge(merged, pricing, left_index=True, right_index=True)\n",
    "# merged = pd.merge(merged, events_dense, left_index=True, right_index=True)\n",
    "# merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667970a-873c-41f1-b5f7-fcc78141522a",
   "metadata": {},
   "source": [
    "# Fetch relevant holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60982a88-7700-4aab-93ff-970db84ccaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_start</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-28</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_start   variable  value\n",
       "0   2009-12-28  ANZAC Day 0.0000\n",
       "1   2010-01-04  ANZAC Day 0.0000\n",
       "2   2010-01-11  ANZAC Day 0.0000\n",
       "3   2010-01-18  ANZAC Day 0.0000\n",
       "4   2010-01-25  ANZAC Day 0.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from random pipeline\n",
    "holidays = pd.read_parquet(\"gs://mtx-ths-uat-au-theseus-pipeline-artifacts/artifacts/816012989105/theseus-simply-energy-20250709103055/run-feature-store-2_-5522238876388687872/model_output/export/holidays.parquet\")\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a67507-c5e3-45bf-9383-32ff39e67240",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m holidays = holidays[(holidays[\u001b[33m\"\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m\"\u001b[39m].isin(model_holidays))].rename(columns={\u001b[33m\"\u001b[39m\u001b[33mperiod_start\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m      3\u001b[39m holidays = holidays.pivot(index=\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m, columns=\u001b[33m\"\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m\"\u001b[39m, values=\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m merged = pd.merge(\u001b[43mmerged\u001b[49m, holidays, left_index=\u001b[38;5;28;01mTrue\u001b[39;00m, right_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m merged\n",
      "\u001b[31mNameError\u001b[39m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "# model_holidays = [\"Christmas Day\", \"Good Friday\", \"New Year's Day\"]\n",
    "# holidays = holidays[(holidays[\"variable\"].isin(model_holidays))].rename(columns={\"period_start\": \"date\"})\n",
    "# holidays = holidays.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n",
    "\n",
    "# merged = pd.merge(merged, holidays, left_index=True, right_index=True)\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cbcda5-9dd7-4829-92b8-50a3c5aebe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:48:27,241 - mmm_eval.comparison.process - INFO - Loading datasets for customer bank_australia_43 with data version 2025-07-10T05:08:31.208146 and node filter default.default.home_loans\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-14 10:48:33,790 - mmm_eval.comparison.load - INFO - Loading events_snapshot\n",
      "2025-07-14 10:48:34,992 - mmm_eval.comparison.load - INFO - Loaded events_snapshot with 3 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-14 10:48:35,988 - mmm_eval.comparison.load - INFO - Loading owned_media_snapshot\n",
      "2025-07-14 10:48:37,101 - mmm_eval.comparison.load - INFO - Loaded owned_media_snapshot with 1 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-14 10:48:38,586 - mmm_eval.comparison.load - INFO - Loading paid_media_snapshot\n",
      "2025-07-14 10:49:41,763 - mmm_eval.comparison.load - INFO - Loaded paid_media_snapshot with 480671 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-14 10:49:42,567 - mmm_eval.comparison.load - INFO - Loading pricing_snapshot\n",
      "2025-07-14 10:49:45,572 - mmm_eval.comparison.load - INFO - Loaded pricing_snapshot with 17667 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-14 10:49:46,322 - mmm_eval.comparison.load - INFO - Loading sales_snapshot\n",
      "2025-07-14 10:49:49,997 - mmm_eval.comparison.load - INFO - Loaded sales_snapshot with 22762 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/mmm_eval/comparison/load.py:356: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lambda x, date_col=date_col, weekly_freq=weekly_freq: x.set_index(date_col)\n",
      "/Users/samuelmccormick/work/mmm-eval/mmm_eval/comparison/load.py:356: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lambda x, date_col=date_col, weekly_freq=weekly_freq: x.set_index(date_col)\n",
      "/Users/samuelmccormick/work/mmm-eval/mmm_eval/comparison/load.py:356: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lambda x, date_col=date_col, weekly_freq=weekly_freq: x.set_index(date_col)\n",
      "/Users/samuelmccormick/work/mmm-eval/mmm_eval/comparison/load.py:356: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lambda x, date_col=date_col, weekly_freq=weekly_freq: x.set_index(date_col)\n"
     ]
    }
   ],
   "source": [
    "from mmm_eval.comparison.process import load_and_process_datasets\n",
    "\n",
    "pipeline_path = \"gs://mtx-ths-uat-au-theseus-pipeline-artifacts/artifacts/816012989105/theseus-simply-energy-20250709103055/run-feature-store-2_-5522238876388687872/model_output/export\"\n",
    "holidays_whitelist = [\"Christmas Day\", \"Good Friday\", \"New Year's Day\"]\n",
    "# why are some of these not showing up?\n",
    "externals_whitelist = ['target_cash_rate_rolling_mean',\n",
    "  'target_cash_rate_smooth_jump',\n",
    "  'employed_total_persons_seasonally_adjusted_feat_differenced',\n",
    "  'consumer_sentiment_feat_centered',\n",
    "  'cpi_raw_trimmed_mean_quad_interpolated',\n",
    "  'migration_total_arrivals_rolling_scaled',\n",
    "  'migration_total_arrivals_mom_pct_change',\n",
    "                      ]\n",
    "node_filter = \"default.default.home_loans\"\n",
    "datasets_processed = load_and_process_datasets(customer_id, data_version, pipeline_path,\n",
    "                                               holidays_whitelist, externals_whitelist, node_filter=node_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b02cd19a-3373-424d-b6e0-ce20c018861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ccaf97-efd1-451b-8257-2b87c3826235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:54:50,347 - mmm_eval.comparison.dataset_processor - INFO - Created DatasetProcessor from raw data with shape (313, 16)\n"
     ]
    }
   ],
   "source": [
    "from mmm_eval.comparison.dataset_processor import DatasetProcessor\n",
    "\n",
    "dp = DatasetProcessor.from_raw_data(datasets_processed, customer_id, data_version, holidays_whitelist,\n",
    "                                    holidays_df_path, node_filter=node_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde51446-ff7c-4732-8c24-f63a09a58809",
   "metadata": {},
   "source": [
    "## Construct PyMC dataset and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2832bf14-d831-47f1-a4e9-edba7fb04f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:55:03,320 - mmm_eval.comparison.dataset_processor - INFO - Transformed dataset for PyMC with shape (313, 16)\n",
      "2025-07-14 10:55:03,321 - mmm_eval.comparison.dataset_processor - INFO - Scaled 8 control columns: ['Good Friday', 'consumer_sentiment_feat_centered', \"New Year's Day\", 'retail_price', 'discount interest rate_event', 'cpi_raw_trimmed_mean_quad_interpolated', 'Christmas Day', 'government scheme launch_event']\n"
     ]
    }
   ],
   "source": [
    "pymc_dataset = dp.get_pymc_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e8ca2ff-d525-4cfc-aa53-bb36eefee5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc_marketing.mmm import GeometricAdstock, LogisticSaturation\n",
    "from mmm_eval.adapters.schemas import PyMCFitSchema, PyMCModelSchema\n",
    "from mmm_eval import PyMCConfig, run_evaluation\n",
    "\n",
    "col_map = dp.get_pymc_column_map()\n",
    "#print(col_map.keys())\n",
    "\n",
    "fast_fit_config = PyMCFitSchema(draws=1000, tune=1000, chains=4, target_accept=0.95, random_seed=42)\n",
    "model_config = PyMCModelSchema(date_column=\"date\", channel_columns=col_map[\"channel_columns\"],\n",
    "                               control_columns=col_map[\"control_columns\"],\n",
    "                               adstock=GeometricAdstock(l_max=8), saturation=LogisticSaturation(),\n",
    "                               time_varying_intercept=False, time_varying_media=False,\n",
    "                               yearly_seasonality=2)\n",
    "config = PyMCConfig(pymc_model_config=model_config, fit_config=fast_fit_config, response_column=\"quantity\",\n",
    "                    revenue_column=\"revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907d07b-12d8-461b-8b3c-864c7fcf6892",
   "metadata": {},
   "source": [
    "### Run evaluation doesn't work - trying to debug why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b282a4a-e82a-4e6d-9ae2-a417f6b5bb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/pymc_marketing/__init__.py'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc_marketing\n",
    "pymc_marketing.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1fbc9c1-cea1-487a-b2c0-558dd54f6592",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Recreate adapter\u001b[39;00m\n\u001b[32m     19\u001b[39m adapter = PyMCAdapter(config)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpymc_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquantity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#adapter.predict(pymc_dataset.rename(columns={\"quantity\": \"response\"}))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/mmm_eval/adapters/pymc.py:128\u001b[39m, in \u001b[36mPyMCAdapter.fit\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    125\u001b[39m y = data[InputDataframeConstants.RESPONSE_COL]\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.model = MMM(**\u001b[38;5;28mself\u001b[39m.model_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28mself\u001b[39m.trace = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28mself\u001b[39m._channel_roi_df = \u001b[38;5;28mself\u001b[39m._compute_channel_contributions(data)\n\u001b[32m    131\u001b[39m \u001b[38;5;28mself\u001b[39m.is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pymc_marketing/model_builder.py:727\u001b[39m, in \u001b[36mModelBuilder.fit\u001b[39m\u001b[34m(self, X, y, progressbar, random_seed, **kwargs)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_model(X, y)\n\u001b[32m    721\u001b[39m sampler_kwargs = create_sample_kwargs(\n\u001b[32m    722\u001b[39m     \u001b[38;5;28mself\u001b[39m.sampler_config,\n\u001b[32m    723\u001b[39m     progressbar,\n\u001b[32m    724\u001b[39m     random_seed,\n\u001b[32m    725\u001b[39m     **kwargs,\n\u001b[32m    726\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model:\n\u001b[32m    728\u001b[39m     idata = pm.sample(**sampler_kwargs)\n\u001b[32m    730\u001b[39m \u001b[38;5;28mself\u001b[39m.post_sample_model_transformation()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pymc/sampling/mcmc.py:964\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[39m\n\u001b[32m    960\u001b[39m t_sampling = time.time() - t_start\n\u001b[32m    962\u001b[39m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[32m    963\u001b[39m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_return\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZarrTrace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pymc/sampling/mcmc.py:1049\u001b[39m, in \u001b[36m_sample_return\u001b[39m\u001b[34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     traces, length = \u001b[43m_choose_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     traces, length = _choose_chains(traces, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pymc/backends/base.py:624\u001b[39m, in \u001b[36m_choose_chains\u001b[39m\u001b[34m(traces, tune)\u001b[39m\n\u001b[32m    622\u001b[39m lengths = [\u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) - tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot enough samples to build a trace.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    626\u001b[39m idxs = np.argsort(lengths)\n\u001b[32m    627\u001b[39m l_sort = np.array(lengths)[idxs]\n",
      "\u001b[31mValueError\u001b[39m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload the deepest dependency first\n",
    "import pymc_marketing.model_builder\n",
    "importlib.reload(pymc_marketing.model_builder)\n",
    "\n",
    "# Reload the module that uses model_builder\n",
    "import pymc_marketing.mmm\n",
    "importlib.reload(pymc_marketing.mmm)\n",
    "\n",
    "# Reload your adapter module\n",
    "import mmm_eval.adapters.pymc\n",
    "importlib.reload(mmm_eval.adapters.pymc)\n",
    "\n",
    "# Now re-import PyMCAdapter from the reloaded module\n",
    "from mmm_eval.adapters.pymc import PyMCAdapter\n",
    "\n",
    "# Recreate adapter\n",
    "adapter = PyMCAdapter(config)\n",
    "\n",
    "adapter.fit(pymc_dataset.rename(columns={\"quantity\": \"response\"}))\n",
    "adapter.predict(pymc_dataset.rename(columns={\"quantity\": \"response\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ea255ff-a3a7-45aa-8db9-b2496a6bc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymc_dataset.columns\n",
    "\n",
    "                                                                              \"Christmas Day\", \"Good Friday\", \"New Year's Day\"]))\n",
    "#result = run_evaluation(framework=\"pymc_marketing\", config=config, data=pymc_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179bd74-e13a-422f-b03c-7d905092425e",
   "metadata": {},
   "source": [
    "## Construct Meridian dataset and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5421237-3745-464f-8229-2285263d41b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'media_channels': ['OOH_brand',\n",
       "  'Search_product',\n",
       "  'Video_brand',\n",
       "  'Display_product',\n",
       "  'Meta_product',\n",
       "  'Display_brand'],\n",
       " 'control_columns': ['Good Friday',\n",
       "  \"New Year's Day\",\n",
       "  'discount interest rate_event',\n",
       "  'Christmas Day',\n",
       "  'government scheme launch_event',\n",
       "  'consumer_sentiment_feat_centered',\n",
       "  'cpi_raw_trimmed_mean_quad_interpolated'],\n",
       " 'non_media_treatment_columns': ['retail_price']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_map = dp.get_meridian_column_map()\n",
    "col_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "892b87f9-3c21-4669-aad8-adca33110196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.adapters.schemas import MeridianModelSpecSchema, MeridianSamplePosteriorSchema, MeridianInputDataBuilderSchema\n",
    "from meridian import constants\n",
    "import tensorflow_probability as tfp\n",
    "from meridian.model import prior_distribution\n",
    "\n",
    "roi_mu = 0.2     # Mu for ROI prior for each media channel.\n",
    "roi_sigma = 0.9  # Sigma for ROI prior for each media channel.\n",
    "prior = prior_distribution.PriorDistribution(\n",
    "    roi_m=tfp.distributions.LogNormal(roi_mu, roi_sigma, name=constants.ROI_M)\n",
    ")\n",
    "\n",
    "# set up Meridian configs\n",
    "model_spec_config = MeridianModelSpecSchema(prior=prior)\n",
    "sample_posterior_config = MeridianSamplePosteriorSchema(n_chains=2, n_adapt=10, n_burnin=10, n_keep=10)\n",
    "idb_config = MeridianInputDataBuilderSchema(date_column=\"date\", media_channels=col_map[\"media_channels\"],\n",
    "                                            channel_spend_columns=col_map[\"media_channels\"],\n",
    "                                            non_media_treatment_columns=col_map.get(\"non_media_treatment_columns\"),\n",
    "                                            control_columns=col_map.get(\"control_columns\"),\n",
    "                                            response_column=\"quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb0187ce-dc8c-4347-aeaa-07f821c53df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.configs.configs import MeridianConfig\n",
    "\n",
    "meridian_config = MeridianConfig(input_data_builder_config=idb_config, model_spec_config=model_spec_config,\n",
    "                        sample_posterior_config=sample_posterior_config, response_column=\"quantity\",\n",
    "                                 revenue_column=\"revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e09522cc-822e-4dcd-be79-22c470730dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:55:21,128 - mmm_eval.comparison.dataset_processor - INFO - Transformed dataset for Meridian with shape (313, 17)\n"
     ]
    }
   ],
   "source": [
    "meridian_dataset = dp.get_meridian_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265b8777-d2ae-4863-b9d1-1ddd1576794a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:55:28,020 - mmm_eval.core.validation_test_orchestrator - INFO - Running test: accuracy\n",
      "2025-07-14 10:55:28,021 - mmm_eval.core.base_validation_test - INFO - Splitting data into train and test sets for accuracy test\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/model.py:66: UserWarning: In a nationally aggregated model, the `media_effects_dist` will be reset to `normal`.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752454528.510294 6747383 service.cc:148] XLA service 0x2ce48d890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752454528.510328 6747383 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1752454528.528864 6747383 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. tau_g_excl_baseline has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. eta_m has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. eta_rf has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. eta_om has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. eta_orf has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. xi_c has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/meridian/model/prior_distribution.py:912: UserWarning: Hierarchical distribution parameters must be deterministically zero for national models. xi_n has been automatically set to Deterministic(0).\n",
      "  warnings.warn(\n",
      "2025-07-14 10:56:14.791072: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-14 10:56:15.556458: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:107] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sanitize_seed/seed\n",
      "W0000 00:00:1752454576.241431 6747383 assert_op.cc:38] Ignoring Assert operator mcmc_retry_init/assert_equal_1/Assert/AssertGuard/Assert\n",
      "2025-07-14 10:57:20,919 - mmm_eval.core.validation_tests - INFO - Saving the test results for accuracy test\n"
     ]
    }
   ],
   "source": [
    "result = run_evaluation(framework=\"meridian\", config=meridian_config, data=meridian_dataset,\n",
    "                        test_names=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061f580-66b6-4b36-b69c-290873e38cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
