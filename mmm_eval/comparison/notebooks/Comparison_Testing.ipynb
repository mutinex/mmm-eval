{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e450d804-52ac-4c29-94a4-4c6b4e4e209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: pandas_gbq in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (0.29.2)\n",
      "Requirement already satisfied: setuptools in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (80.9.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (20.0.0)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.9.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.10.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.25.1)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0,>=3.4.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (3.34.0)\n",
      "Requirement already satisfied: packaging>=22.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas_gbq) (25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2.32.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (2.9.0.post0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.73.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery<4.0.0,>=3.4.2->pandas_gbq) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0,>=2.10.2->pandas_gbq) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.13.0->pandas_gbq) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas>=1.1.4->pandas_gbq) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from pandas>=1.1.4->pandas_gbq) (2025.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "!pip install pandas_gbq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_gbq as bq\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from google.oauth2 import service_account\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "from mmm_eval.comparison.load import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20df2b45-a7a9-4a8a-8bd0-358ff2109bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:30,224 - mmm_eval.comparison.load - INFO - Loading discounts_snapshot\n",
      "2025-07-22 10:20:34,244 - mmm_eval.comparison.load - INFO - Loaded discounts_snapshot with 7536 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:35,365 - mmm_eval.comparison.load - INFO - Loading events_snapshot\n",
      "2025-07-22 10:20:37,491 - mmm_eval.comparison.load - INFO - Loaded events_snapshot with 8 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:38,326 - mmm_eval.comparison.load - INFO - Loading offers_snapshot\n",
      "2025-07-22 10:20:39,639 - mmm_eval.comparison.load - INFO - Loaded offers_snapshot with 1933 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:40,448 - mmm_eval.comparison.load - INFO - Loading owned_media_snapshot\n",
      "2025-07-22 10:20:41,913 - mmm_eval.comparison.load - INFO - Loaded owned_media_snapshot with 2241 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:42,855 - mmm_eval.comparison.load - INFO - Loading paid_media_snapshot\n",
      "2025-07-22 10:20:51,066 - mmm_eval.comparison.load - INFO - Loaded paid_media_snapshot with 44746 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:51,945 - mmm_eval.comparison.load - INFO - Loading pricing_snapshot\n",
      "2025-07-22 10:20:58,311 - mmm_eval.comparison.load - INFO - Loaded pricing_snapshot with 50199 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-22 10:20:59,005 - mmm_eval.comparison.load - INFO - Loading sales_snapshot\n",
      "2025-07-22 10:21:18,040 - mmm_eval.comparison.load - INFO - Loaded sales_snapshot with 186077 rows\n"
     ]
    }
   ],
   "source": [
    "from mmm_eval.comparison.load import get_datasets\n",
    "stage = \"warchest-staging-323804\"  # \"warchest-develop\"\n",
    "import os\n",
    "\n",
    "# customer_id = \"belong_64\"\n",
    "# dataset_name = customer_id + '_datamart'\n",
    "# data_version = \"2025-07-10T05:08:31.208146\"\n",
    "\n",
    "customer_id = \"belong_64\"\n",
    "dataset_name = customer_id + '_datamart'\n",
    "data_version = \"2025-07-07T05:59:08.517992\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/samuelmccormick/.config/gcloud/application_default_credentials.json\"\n",
    "project_id = \"mtx-dataos-datalake-prod\"\n",
    "\n",
    "customer_name = customer_id.rpartition(\"_\")[0]\n",
    "datasets = get_datasets(project_id, dataset_name, data_version, node_filter=\"default_default_internet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e8b94-a221-4a7f-9c1d-652c088e6272",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "Pass the following args:\n",
    "\n",
    "- Customer slug\n",
    "- Data version\n",
    "- Holiday names\n",
    "- Pipeline link\n",
    "\n",
    "then\n",
    "\n",
    "- process all datasets and merge them together\n",
    "- call functions to construct data configs for each framework\n",
    "- transformations\n",
    "  - PyMC: maxabs scale all control columns\n",
    "  - Meridian: add dummy geo column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed1427-86f6-457b-b7eb-428abecaff33",
   "metadata": {},
   "source": [
    "## Turn into DFs for PyMC\n",
    "- Restrict to node(s) of interest\n",
    "- Convert all datasets to weekly\n",
    "- Load holidays and process them\n",
    "- Merge together into a single dataframe\n",
    "- Set up config fields based on dataset column mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d80a706-8d09-4bdc-9315-66c4ec83ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmm_eval.comparison.utils as utils\n",
    "from mmm_eval.comparison.load import aggregate_to_node_level, convert_df_to_weekly\n",
    "\n",
    "# sales_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"sales_snapshot\"],\n",
    "#     numerical_columns=[\"quantity\", \"value\"],\n",
    "#     downsample_method_to_daily={\"value\": utils.DownsampleMethod.UNIFORM, \"quantity\": utils.DownsampleMethod.UNIFORM},\n",
    "#     agg_method_to_weekly={\"value\": \"sum\", \"quantity\": \"sum\"},\n",
    "# )\n",
    "\n",
    "# sales = aggregate_to_node_level(\n",
    "#     sales_weekly, extra_group_cols=[], agg_mapping={\"quantity\": \"sum\", \"value\": \"sum\"}\n",
    "# )\n",
    "\n",
    "# sales_proc = sales[[\"date\", \"quantity\", \"value\"]].set_index(\"date\").rename(columns={\"value\": \"revenue\"})\n",
    "# sales_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f94f689-b7c8-4b93-858c-aa8ea11b05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns = [\n",
    "#     \"impressions\",\n",
    "#     \"funnel_stage\",\n",
    "#     \"tarp\",\n",
    "#     \"fees\",\n",
    "# ]\n",
    "\n",
    "# if \"impressions\" in datasets[\"paid_media_snapshot\"].columns:\n",
    "#     datasets['paid_media_snapshot'].drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# # Convert to weekly then aggregate to node or lower level\n",
    "# paid_media_weekly = convert_df_to_weekly(\n",
    "#     datasets['paid_media_snapshot'],\n",
    "#     numerical_columns=[\"spend\"],\n",
    "#     downsample_method_to_daily={\n",
    "#         \"spend\": utils.DownsampleMethod.UNIFORM,\n",
    "#     },\n",
    "#     agg_method_to_weekly={\n",
    "#         \"spend\": \"sum\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# paid_media = aggregate_to_node_level(\n",
    "#     paid_media_weekly, extra_group_cols=[\"media_channel\", \"marketing_spend_impact\"], agg_mapping={\"spend\": \"sum\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786bacc1-0712-46f0-b309-e4efbd859f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot out by spend impact\n",
    "# pivoted = paid_media.pivot(columns=[\"media_channel\", \"marketing_spend_impact\"], values=\"spend\", index=\"date\")\n",
    "# pivoted.columns = ['_'.join(col).strip() for col in pivoted.columns.values]\n",
    "# paid_media_pivoted = pivoted.fillna(0)\n",
    "# paid_media_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf59571-dd24-4c60-a6c2-16ff9cf46a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricing_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"pricing_snapshot\"],\n",
    "#     numerical_columns=[\"retail_price\"],\n",
    "#     downsample_method_to_daily={\n",
    "#         \"retail_price\": utils.DownsampleMethod.REPLICA,\n",
    "#     },\n",
    "#     agg_method_to_weekly={\n",
    "#         \"retail_price\": \"mean\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# pricing = aggregate_to_node_level(\n",
    "#     pricing_weekly, extra_group_cols=[\"company\"], agg_mapping={\"retail_price\": \"mean\"}\n",
    "# )\n",
    "# # alternative is to include competitor prices as separate cols\n",
    "# pricing = pricing[pricing[\"company\"]==\"bank_australia\"]\n",
    "# pricing = pricing[[\"date\", \"retail_price\"]].set_index(\"date\").ffill()\n",
    "# pricing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea4c77a-5986-40d7-8f3a-4b4bda84debc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelmccormick/work/mmm-eval/mmm_eval/comparison/load.py:360: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-09</th>\n",
       "      <td>360.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>420.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-23</th>\n",
       "      <td>420.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>420.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-06</th>\n",
       "      <td>420.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            offer_value\n",
       "date                   \n",
       "2021-08-09     360.0000\n",
       "2021-08-16     420.0000\n",
       "2021-08-23     420.0000\n",
       "2021-08-30     420.0000\n",
       "2021-09-06     420.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_weekly = convert_df_to_weekly(\n",
    "    datasets[\"offers_snapshot\"],\n",
    "    numerical_columns=[\"offer_value\", \"offer_measure\"],\n",
    "    downsample_method_to_daily={\n",
    "        \"retail_price\": utils.DownsampleMethod.UNIFORM,\n",
    "    },\n",
    "    agg_method_to_weekly={\n",
    "        \"offer_measure\": \"sum\",\n",
    "        \"offer_value\": \"sum\",\n",
    "    },\n",
    ")\n",
    "\n",
    "offers = aggregate_to_node_level(\n",
    "    offers_weekly, extra_group_cols=[\"company_name\"], agg_mapping={\n",
    "            \"offer_measure\": \"sum\",\n",
    "            \"offer_value\": \"sum\",\n",
    "        },\n",
    ")\n",
    "# alternative is to include competitor prices as separate cols\n",
    "offers = offers[offers[\"company_name\"].isin([\"belong\", \"default\"])]\n",
    "value_col = \"offer_measure\" if offers[\"offer_value\"].isnull().all() else \"offer_value\"\n",
    "    \n",
    "offers = offers[[\"date\", value_col]].set_index(\"date\").ffill()\n",
    "offers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "662259d4-b7e5-416e-87b5-9026faaa5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_weekly = convert_df_to_weekly(\n",
    "#     datasets[\"events_snapshot\"],\n",
    "#     numerical_columns=[\"duration\",],\n",
    "#     downsample_method_to_daily=utils.DownsampleMethod.REPLICA,\n",
    "#     agg_method_to_weekly={\n",
    "#         \"duration\": \"sum\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# events = aggregate_to_node_level(\n",
    "#     events_weekly, extra_group_cols=[\"event_type\", \"event_purpose\"], agg_mapping={\"duration\": \"sum\"}\n",
    "# )\n",
    "# events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a12d1a4-b348-475c-91d2-8d675a3b1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_matrix = pd.crosstab(events[\"date\"], events[\"event_purpose\"])\n",
    "# binary_matrix = binary_matrix.astype(bool).astype(int)\n",
    "# events_dense = binary_matrix.reindex(sales_proc.index, fill_value=0)\n",
    "# events_dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8b1022-b247-42c6-ba11-6870bc92c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = pd.merge(sales_proc, paid_media_pivoted, left_index=True, right_index=True)\n",
    "# merged = pd.merge(merged, pricing, left_index=True, right_index=True)\n",
    "# merged = pd.merge(merged, events_dense, left_index=True, right_index=True)\n",
    "# merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667970a-873c-41f1-b5f7-fcc78141522a",
   "metadata": {},
   "source": [
    "# Fetch relevant holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60982a88-7700-4aab-93ff-970db84ccaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_start</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-28</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>ANZAC Day</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_start   variable  value\n",
       "0   2009-12-28  ANZAC Day 0.0000\n",
       "1   2010-01-04  ANZAC Day 0.0000\n",
       "2   2010-01-11  ANZAC Day 0.0000\n",
       "3   2010-01-18  ANZAC Day 0.0000\n",
       "4   2010-01-25  ANZAC Day 0.0000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from random pipeline\n",
    "#holidays = pd.read_parquet(\"gs://mtx-ths-uat-au-theseus-pipeline-artifacts/artifacts/816012989105/theseus-simply-energy-20250709103055/run-feature-store-2_-5522238876388687872/model_output/export/holidays.parquet\")\n",
    "#holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a67507-c5e3-45bf-9383-32ff39e67240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_holidays = [\"Christmas Day\", \"Good Friday\", \"New Year's Day\"]\n",
    "# holidays = holidays[(holidays[\"variable\"].isin(model_holidays))].rename(columns={\"period_start\": \"date\"})\n",
    "# holidays = holidays.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n",
    "\n",
    "# merged = pd.merge(merged, holidays, left_index=True, right_index=True)\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3adc958-5fe2-4ddb-ab68-3953ab2dbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_parquet(\"gs://mtx-ths-dev-us-theseus-pipeline-artifacts/artifacts/757046730850/theseus-xero-20250715122215/run-feature-store-2_-6097048265306406912/model_output/export/externals.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c623d12-b36c-42cd-b410-148d7a4a8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.listdir(\"../data\")\n",
    "chicken = pd.read_parquet(\"../data/chicken_treat.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959a2cd6-13af-4c0a-8ad3-1ebc6aa79f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2019-12-30   0.0010\n",
       "2020-01-06   0.0010\n",
       "2020-01-13   0.0010\n",
       "2020-01-20   0.0010\n",
       "2020-01-27   0.0010\n",
       "              ...  \n",
       "2025-04-21   0.0010\n",
       "2025-04-28   0.0010\n",
       "2025-05-05   0.0010\n",
       "2025-05-12   0.0010\n",
       "2025-05-19   0.0010\n",
       "Name: cpi_trimmed_mean_feat_smoothed, Length: 282, dtype: Float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicken[\"cpi_trimmed_mean_feat_smoothed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37cbcda5-9dd7-4829-92b8-50a3c5aebe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:57:34,914 - mmm_eval.comparison.process - INFO - Loading datasets for customer xero_51 with data version 2025-07-09T06:24:18.236648 and node filter None\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 10:57:38,527 - mmm_eval.comparison.load - INFO - Loading earned_media_snapshot\n",
      "2025-07-16 10:57:39,291 - mmm_eval.comparison.load - INFO - Loaded earned_media_snapshot with 230 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 10:57:40,077 - mmm_eval.comparison.load - WARNING - events_snapshot was not found in datamart\n",
      "2025-07-16 10:57:41,028 - mmm_eval.comparison.load - INFO - Loading offers_snapshot\n",
      "2025-07-16 10:57:42,009 - mmm_eval.comparison.load - INFO - Loaded offers_snapshot with 26 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 10:57:42,574 - mmm_eval.comparison.load - INFO - Loading owned_media_snapshot\n",
      "2025-07-16 10:57:43,346 - mmm_eval.comparison.load - INFO - Loaded owned_media_snapshot with 2174 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 10:57:43,933 - mmm_eval.comparison.load - INFO - Loading paid_media_snapshot\n",
      "2025-07-16 11:08:29,755 - mmm_eval.comparison.load - INFO - Loaded paid_media_snapshot with 4776328 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 11:08:30,812 - mmm_eval.comparison.load - INFO - Loading pricing_snapshot\n",
      "2025-07-16 11:08:31,790 - mmm_eval.comparison.load - INFO - Loaded pricing_snapshot with 8 rows\n",
      "/Users/samuelmccormick/work/mmm-eval/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-07-16 11:08:32,441 - mmm_eval.comparison.load - INFO - Loading sales_snapshot\n",
      "2025-07-16 11:08:33,427 - mmm_eval.comparison.load - INFO - Loaded sales_snapshot with 2082 rows\n",
      "<string>:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     33\u001b[39m externals_whitelist = [\n\u001b[32m     34\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcpi_trimmed_mean_feat_smoothed\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     35\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mconsumer_sentiment_feat_centered\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     36\u001b[39m   \u001b[33m'\u001b[39m\u001b[33memployed_total_persons_seasonally_adjusted_feat_differenced\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     37\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mtarget_cash_rate_rolling_mean\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     38\u001b[39m                       ]\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#node_filter = \"default_consideration_at_store\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m datasets_processed = \u001b[43mload_and_process_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomer_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mholidays_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternals_whitelist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# node_filter=node_filter)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/mmm_eval/comparison/process.py:252\u001b[39m, in \u001b[36mload_and_process_datasets\u001b[39m\u001b[34m(customer_id, data_version, pipeline_data_path, holidays_whitelist, externals_whitelist, node_filter)\u001b[39m\n\u001b[32m    249\u001b[39m externals = externals[(externals[\u001b[33m\"\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m\"\u001b[39m].isin(externals_whitelist))].rename(columns={\u001b[33m\"\u001b[39m\u001b[33mperiod_start\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    251\u001b[39m company_name = \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m.join(customer_id.split(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)[:-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholidays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternals\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/mmm_eval/comparison/process.py:177\u001b[39m, in \u001b[36mprocess_datasets\u001b[39m\u001b[34m(datasets, company_name, holidays, externals)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_datasets\u001b[39m(datasets: \u001b[38;5;28mdict\u001b[39m, company_name: \u001b[38;5;28mstr\u001b[39m, holidays: pd.DataFrame,\n\u001b[32m    175\u001b[39m                      externals: pd.DataFrame):\n\u001b[32m    176\u001b[39m     sales_processed = process_sales(datasets[\u001b[33m\"\u001b[39m\u001b[33msales_snapshot\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     paid_media_processed = \u001b[43mprocess_paid_media\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaid_media_snapshot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     column_map = {\u001b[33m\"\u001b[39m\u001b[33mpaid_media\u001b[39m\u001b[33m\"\u001b[39m: paid_media_processed.columns.tolist()}\n\u001b[32m    180\u001b[39m     processed = [sales_processed, paid_media_processed]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/mmm_eval/comparison/process.py:49\u001b[39m, in \u001b[36mprocess_paid_media\u001b[39m\u001b[34m(paid_media_df)\u001b[39m\n\u001b[32m     46\u001b[39m     paid_media_df.drop(columns=drop_columns, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Convert to weekly then aggregate to node or lower level\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m paid_media_weekly = \u001b[43mconvert_df_to_weekly\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaid_media_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownsample_method_to_daily\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDownsampleMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUNIFORM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43magg_method_to_weekly\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m paid_media = aggregate_to_node_level(\n\u001b[32m     61\u001b[39m     paid_media_weekly, extra_group_cols=[\u001b[33m\"\u001b[39m\u001b[33mmedia_channel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmarketing_spend_impact\u001b[39m\u001b[33m\"\u001b[39m], agg_mapping={\u001b[33m\"\u001b[39m\u001b[33mspend\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# pivot out by spend impact\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:36\u001b[39m, in \u001b[36mconvert_df_to_weekly\u001b[39m\u001b[34m(df, numerical_columns, agg_method_to_weekly, downsample_method_to_daily, date_col, freq_col, weekly_freq, flag_overflow)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1824\u001b[39m, in \u001b[36mGroupBy.apply\u001b[39m\u001b[34m(self, func, include_groups, *args, **kwargs)\u001b[39m\n\u001b[32m   1822\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1823\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1824\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1825\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1826\u001b[39m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj, Series)\n\u001b[32m   1827\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1828\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._selected_obj.shape != \u001b[38;5;28mself\u001b[39m._obj_with_exclusions.shape\n\u001b[32m   1829\u001b[39m         ):\n\u001b[32m   1830\u001b[39m             warnings.warn(\n\u001b[32m   1831\u001b[39m                 message=_apply_groupings_depr.format(\n\u001b[32m   1832\u001b[39m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1835\u001b[39m                 stacklevel=find_stack_level(),\n\u001b[32m   1836\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1885\u001b[39m, in \u001b[36mGroupBy._python_apply_general\u001b[39m\u001b[34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[39m\n\u001b[32m   1850\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1851\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_python_apply_general\u001b[39m(\n\u001b[32m   1852\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1857\u001b[39m     is_agg: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1858\u001b[39m ) -> NDFrameT:\n\u001b[32m   1859\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1860\u001b[39m \u001b[33;03m    Apply function f in python space\u001b[39;00m\n\u001b[32m   1861\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1883\u001b[39m \u001b[33;03m        data after applying f\u001b[39;00m\n\u001b[32m   1884\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1885\u001b[39m     values, mutated = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1886\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1887\u001b[39m         not_indexed_same = mutated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:919\u001b[39m, in \u001b[36mBaseGrouper.apply_groupwise\u001b[39m\u001b[34m(self, f, data, axis)\u001b[39m\n\u001b[32m    917\u001b[39m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[32m    918\u001b[39m group_axes = group.axes\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m res = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[32m    921\u001b[39m     mutated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:36\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x, date_col, weekly_freq)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/generic.py:9790\u001b[39m, in \u001b[36mNDFrame.resample\u001b[39m\u001b[34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[39m\n\u001b[32m   9787\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   9788\u001b[39m     convention = \u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m9790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSeries | DataFrame\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9795\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9800\u001b[39m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9801\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:2050\u001b[39m, in \u001b[36mget_resampler\u001b[39m\u001b[34m(obj, kind, **kwds)\u001b[39m\n\u001b[32m   2046\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2047\u001b[39m \u001b[33;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[32m   2048\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2049\u001b[39m tg = TimeGrouper(obj, **kwds)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2050\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:2231\u001b[39m, in \u001b[36mTimeGrouper._get_resampler\u001b[39m\u001b[34m(self, obj, kind)\u001b[39m\n\u001b[32m   2229\u001b[39m _, ax, _ = \u001b[38;5;28mself\u001b[39m._set_grouper(obj, gpr_index=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   2230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, DatetimeIndex):\n\u001b[32m-> \u001b[39m\u001b[32m2231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatetimeIndexResampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimegrouper\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2235\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgpr_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, PeriodIndex) \u001b[38;5;129;01mor\u001b[39;00m kind == \u001b[33m\"\u001b[39m\u001b[33mperiod\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, PeriodIndex):\n\u001b[32m   2241\u001b[39m         \u001b[38;5;66;03m# GH#53481\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:187\u001b[39m, in \u001b[36mResampler.__init__\u001b[39m\u001b[34m(self, obj, timegrouper, axis, kind, gpr_index, group_keys, selection, include_groups)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.include_groups = include_groups\n\u001b[32m    184\u001b[39m \u001b[38;5;28mself\u001b[39m.obj, \u001b[38;5;28mself\u001b[39m.ax, \u001b[38;5;28mself\u001b[39m._indexer = \u001b[38;5;28mself\u001b[39m._timegrouper._set_grouper(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert_obj(obj), sort=\u001b[38;5;28;01mTrue\u001b[39;00m, gpr_index=gpr_index\n\u001b[32m    186\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[38;5;28mself\u001b[39m.binner, \u001b[38;5;28mself\u001b[39m._grouper = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_binner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m._selection = selection\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timegrouper.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:252\u001b[39m, in \u001b[36mResampler._get_binner\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_binner\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    248\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m    Create the BinGrouper, assume that self.set_grouper(obj)\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m    has already been called.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     binner, bins, binlabels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_binner_for_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) == \u001b[38;5;28mlen\u001b[39m(binlabels)\n\u001b[32m    254\u001b[39m     bin_grouper = BinGrouper(bins, binlabels, indexer=\u001b[38;5;28mself\u001b[39m._indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:1741\u001b[39m, in \u001b[36mDatetimeIndexResampler._get_binner_for_time\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.kind == \u001b[33m\"\u001b[39m\u001b[33mperiod\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timegrouper._get_time_period_bins(\u001b[38;5;28mself\u001b[39m.ax)\n\u001b[32m-> \u001b[39m\u001b[32m1741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timegrouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_time_bins\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:2298\u001b[39m, in \u001b[36mTimeGrouper._get_time_bins\u001b[39m\u001b[34m(self, ax)\u001b[39m\n\u001b[32m   2293\u001b[39m     binner = labels = DatetimeIndex(\n\u001b[32m   2294\u001b[39m         data=[], freq=\u001b[38;5;28mself\u001b[39m.freq, name=ax.name, dtype=ax.dtype\n\u001b[32m   2295\u001b[39m     )\n\u001b[32m   2296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m binner, [], labels\n\u001b[32m-> \u001b[39m\u001b[32m2298\u001b[39m first, last = \u001b[43m_get_timestamp_range_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2299\u001b[39m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2300\u001b[39m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2302\u001b[39m \u001b[43m    \u001b[49m\u001b[43munit\u001b[49m\u001b[43m=\u001b[49m\u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2304\u001b[39m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2305\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2307\u001b[39m \u001b[38;5;66;03m# GH #12037\u001b[39;00m\n\u001b[32m   2308\u001b[39m \u001b[38;5;66;03m# use first/last directly instead of call replace() on them\u001b[39;00m\n\u001b[32m   2309\u001b[39m \u001b[38;5;66;03m# because replace() will swallow the nanosecond part\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2312\u001b[39m \u001b[38;5;66;03m# GH 25758: If DST lands at midnight (e.g. 'America/Havana'), user feedback\u001b[39;00m\n\u001b[32m   2313\u001b[39m \u001b[38;5;66;03m# has noted that ambiguous=True provides the most sensible result\u001b[39;00m\n\u001b[32m   2314\u001b[39m binner = labels = date_range(\n\u001b[32m   2315\u001b[39m     freq=\u001b[38;5;28mself\u001b[39m.freq,\n\u001b[32m   2316\u001b[39m     start=first,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2322\u001b[39m     unit=ax.unit,\n\u001b[32m   2323\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/mmm-eval/.venv/lib/python3.11/site-packages/pandas/core/resample.py:2629\u001b[39m, in \u001b[36m_get_timestamp_range_edges\u001b[39m\u001b[34m(first, last, freq, unit, closed, origin, offset)\u001b[39m\n\u001b[32m   2627\u001b[39m         first = Timestamp(freq.rollback(first))\n\u001b[32m   2628\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m         first = Timestamp(\u001b[43mfirst\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m)\n\u001b[32m   2631\u001b[39m     last = Timestamp(last + freq)\n\u001b[32m   2633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m first, last\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/offsets.pyx:481\u001b[39m, in \u001b[36mpandas._libs.tslibs.offsets.BaseOffset.__rsub__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/offsets.pyx:463\u001b[39m, in \u001b[36mpandas._libs.tslibs.offsets.BaseOffset.__add__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/offsets.pyx:141\u001b[39m, in \u001b[36mpandas._libs.tslibs.offsets.apply_wraps.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/offsets.pyx:3387\u001b[39m, in \u001b[36mpandas._libs.tslibs.offsets.Week._apply\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from mmm_eval.comparison.process import load_and_process_datasets\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/samuelmccormick/.config/gcloud/application_default_credentials.json\"\n",
    "\n",
    "# belong.default.internet\n",
    "#customer_id = \"belong_64\"\n",
    "#data_version = \"2025-07-07T05:59:08.517992\"\n",
    "#pipeline_path = \"gs://mtx-ths-uat-au-theseus-pipeline-artifacts/artifacts/816012989105/theseus-belong-20250714150222/run-feature-store-2_490770313592700928/model_output/export\"\n",
    "\n",
    "# xero (default.smb.smb)\n",
    "customer_id = \"xero_51\"\n",
    "data_version = \"2025-07-09T06:24:18.236648\"\n",
    "pipeline_path = \"gs://mtx-ths-dev-us-theseus-pipeline-artifacts/artifacts/757046730850/theseus-xero-20250715122215/run-feature-store-2_-6097048265306406912/model_output/export\"\n",
    "\n",
    "# chicken_treat (default.consideration.at_store)\n",
    "#customer_id = \"chicken_treat_53\"\n",
    "#data_version = \"2025-06-25T00:18:48.379609\"\n",
    "#pipeline_path = \"gs://mtx-ths-uat-us-theseus-pipeline-artifacts/artifacts/816012989105/theseus-chicken-treat-20250627150301/run-feature-store-2_5949443570921373696/model_output/export\"\n",
    "\n",
    "# original (default.core.gas)\n",
    "\n",
    "\n",
    "holidays_whitelist = [\n",
    "  'BAS Deadline (Q1)',\n",
    "  'BAS Deadline (Q2)',\n",
    "  'BAS Deadline (Q3)',\n",
    "  'BAS Deadline (Q4)',\n",
    "  'Christmas Day',\n",
    "  'EOFY',\n",
    "  'Lockdown Start',\n",
    "  'Lodgement Deadline',\n",
    "  'National Day of Mourning for Queen Elizabeth II',\n",
    "  \"New Year's Day\",\n",
    "]\n",
    "# why are some of these not showing up?\n",
    "externals_whitelist = [\n",
    "  'cpi_trimmed_mean_feat_smoothed',\n",
    "  'consumer_sentiment_feat_centered',\n",
    "  'employed_total_persons_seasonally_adjusted_feat_differenced',\n",
    "  'target_cash_rate_rolling_mean',\n",
    "                      ]\n",
    "#node_filter = \"default_consideration_at_store\"\n",
    "datasets_processed = load_and_process_datasets(customer_id, data_version, pipeline_path,\n",
    "                                               holidays_whitelist, externals_whitelist) # node_filter=node_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b02cd19a-3373-424d-b6e0-ce20c018861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>offer_value</th>\n",
       "      <th>discounts_value</th>\n",
       "      <th>Australia Day</th>\n",
       "      <th>Christmas Day</th>\n",
       "      <th>Good Friday</th>\n",
       "      <th>New Year's Day</th>\n",
       "      <th>consumer_sentiment_feat_centered</th>\n",
       "      <th>cpi_trimmed_mean_feat_smoothed</th>\n",
       "      <th>foot_traffic_vol</th>\n",
       "      <th>foot_traffic_vol_feat_weekly_pct_chng_smoothed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>50401.0000</td>\n",
       "      <td>775599.1900</td>\n",
       "      <td>8.2211</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>514.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.5900</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>48033.0000</td>\n",
       "      <td>-0.0925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>73823.0000</td>\n",
       "      <td>1080639.3650</td>\n",
       "      <td>8.6603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>867.6800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6114</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>57194.5000</td>\n",
       "      <td>-0.0358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>73141.0000</td>\n",
       "      <td>1074458.4866</td>\n",
       "      <td>8.4185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>859.2400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6364</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>60053.0000</td>\n",
       "      <td>-0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20</th>\n",
       "      <td>74204.0000</td>\n",
       "      <td>1082677.7583</td>\n",
       "      <td>8.4341</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>827.9200</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6613</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64027.0000</td>\n",
       "      <td>0.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-27</th>\n",
       "      <td>75712.0000</td>\n",
       "      <td>1119818.7200</td>\n",
       "      <td>8.5527</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>811.2900</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6834</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>51309.0000</td>\n",
       "      <td>0.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21</th>\n",
       "      <td>85247.0000</td>\n",
       "      <td>1718480.7700</td>\n",
       "      <td>9.9997</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11130.7300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.8888</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>25523.5000</td>\n",
       "      <td>-0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-28</th>\n",
       "      <td>87259.0000</td>\n",
       "      <td>1674810.9600</td>\n",
       "      <td>10.2538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>22151.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9098</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>31476.0000</td>\n",
       "      <td>-0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-05</th>\n",
       "      <td>85661.0000</td>\n",
       "      <td>1663532.0300</td>\n",
       "      <td>10.2308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>26937.4900</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9244</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>33582.5000</td>\n",
       "      <td>0.0171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-12</th>\n",
       "      <td>84547.0000</td>\n",
       "      <td>1648193.0000</td>\n",
       "      <td>9.5551</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>28053.1300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9404</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>31502.0000</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-19</th>\n",
       "      <td>85814.0000</td>\n",
       "      <td>1684688.2000</td>\n",
       "      <td>9.8530</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>27801.4400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9563</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>30751.5000</td>\n",
       "      <td>0.0536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             quantity      revenue  retail_price  offer_value  \\\n",
       "date                                                            \n",
       "2019-12-30 50401.0000  775599.1900        8.2211       0.0000   \n",
       "2020-01-06 73823.0000 1080639.3650        8.6603       0.0000   \n",
       "2020-01-13 73141.0000 1074458.4866        8.4185       0.0000   \n",
       "2020-01-20 74204.0000 1082677.7583        8.4341       0.0000   \n",
       "2020-01-27 75712.0000 1119818.7200        8.5527       0.0000   \n",
       "...               ...          ...           ...          ...   \n",
       "2025-04-21 85247.0000 1718480.7700        9.9997       0.0000   \n",
       "2025-04-28 87259.0000 1674810.9600       10.2538       0.0000   \n",
       "2025-05-05 85661.0000 1663532.0300       10.2308       0.0000   \n",
       "2025-05-12 84547.0000 1648193.0000        9.5551       0.0000   \n",
       "2025-05-19 85814.0000 1684688.2000        9.8530       0.0000   \n",
       "\n",
       "            discounts_value  Australia Day  Christmas Day  Good Friday  \\\n",
       "date                                                                     \n",
       "2019-12-30         514.8000         0.0000         0.0000       0.0000   \n",
       "2020-01-06         867.6800         0.0000         0.0000       0.0000   \n",
       "2020-01-13         859.2400         0.0000         0.0000       0.0000   \n",
       "2020-01-20         827.9200         1.0000         0.0000       0.0000   \n",
       "2020-01-27         811.2900         0.0000         0.0000       0.0000   \n",
       "...                     ...            ...            ...          ...   \n",
       "2025-04-21       11130.7300         0.0000         0.0000       0.0000   \n",
       "2025-04-28       22151.0400         0.0000         0.0000       0.0000   \n",
       "2025-05-05       26937.4900         0.0000         0.0000       0.0000   \n",
       "2025-05-12       28053.1300         0.0000         0.0000       0.0000   \n",
       "2025-05-19       27801.4400         0.0000         0.0000       0.0000   \n",
       "\n",
       "            New Year's Day  consumer_sentiment_feat_centered  \\\n",
       "date                                                           \n",
       "2019-12-30          1.0000                           -0.5900   \n",
       "2020-01-06          0.0000                           -0.6114   \n",
       "2020-01-13          0.0000                           -0.6364   \n",
       "2020-01-20          0.0000                           -0.6613   \n",
       "2020-01-27          0.0000                           -0.6834   \n",
       "...                    ...                               ...   \n",
       "2025-04-21          0.0000                           -0.8888   \n",
       "2025-04-28          0.0000                           -0.9098   \n",
       "2025-05-05          0.0000                           -0.9244   \n",
       "2025-05-12          0.0000                           -0.9404   \n",
       "2025-05-19          0.0000                           -0.9563   \n",
       "\n",
       "            cpi_trimmed_mean_feat_smoothed  foot_traffic_vol  \\\n",
       "date                                                           \n",
       "2019-12-30                          0.0010        48033.0000   \n",
       "2020-01-06                          0.0010        57194.5000   \n",
       "2020-01-13                          0.0010        60053.0000   \n",
       "2020-01-20                          0.0010        64027.0000   \n",
       "2020-01-27                          0.0010        51309.0000   \n",
       "...                                    ...               ...   \n",
       "2025-04-21                          0.0010        25523.5000   \n",
       "2025-04-28                          0.0010        31476.0000   \n",
       "2025-05-05                          0.0010        33582.5000   \n",
       "2025-05-12                          0.0010        31502.0000   \n",
       "2025-05-19                          0.0010        30751.5000   \n",
       "\n",
       "            foot_traffic_vol_feat_weekly_pct_chng_smoothed  \n",
       "date                                                        \n",
       "2019-12-30                                         -0.0925  \n",
       "2020-01-06                                         -0.0358  \n",
       "2020-01-13                                         -0.0078  \n",
       "2020-01-20                                          0.0661  \n",
       "2020-01-27                                          0.0271  \n",
       "...                                                    ...  \n",
       "2025-04-21                                         -0.0935  \n",
       "2025-04-28                                         -0.0088  \n",
       "2025-05-05                                          0.0171  \n",
       "2025-05-12                                          0.0173  \n",
       "2025-05-19                                          0.0536  \n",
       "\n",
       "[282 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccaf97-efd1-451b-8257-2b87c3826235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.comparison.dataset_processor import DatasetProcessor\n",
    "\n",
    "dp = DatasetProcessor.from_raw_data(datasets_processed, customer_id, data_version, holidays_whitelist,\n",
    "                                    pipeline_path, node_filter=node_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde51446-ff7c-4732-8c24-f63a09a58809",
   "metadata": {},
   "source": [
    "## Construct PyMC dataset and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d424992-da57-4ee8-a581-c1d539ae9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.listdir(\"../../comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d2939cf-e9d9-4445-a7b6-bfdc1a2fb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_processed.to_parquet(\"../../comparison/data/chicken_treat_consideration_at_store.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832bf14-d831-47f1-a4e9-edba7fb04f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymc_dataset = dp.get_pymc_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ca2ff-d525-4cfc-aa53-bb36eefee5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc_marketing.mmm import GeometricAdstock, LogisticSaturation\n",
    "from mmm_eval.adapters.schemas import PyMCFitSchema, PyMCModelSchema\n",
    "from mmm_eval import PyMCConfig, run_evaluation\n",
    "\n",
    "col_map = dp.get_pymc_column_map()\n",
    "#print(col_map.keys())\n",
    "\n",
    "fast_fit_config = PyMCFitSchema(draws=1000, tune=1000, chains=4, target_accept=0.95, random_seed=42)\n",
    "model_config = PyMCModelSchema(date_column=\"date\", channel_columns=col_map[\"channel_columns\"],\n",
    "                               control_columns=col_map[\"control_columns\"],\n",
    "                               adstock=GeometricAdstock(l_max=8), saturation=LogisticSaturation(),\n",
    "                               time_varying_intercept=False, time_varying_media=False,\n",
    "                               yearly_seasonality=2)\n",
    "config = PyMCConfig(pymc_model_config=model_config, fit_config=fast_fit_config, response_column=\"quantity\",\n",
    "                    revenue_column=\"revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907d07b-12d8-461b-8b3c-864c7fcf6892",
   "metadata": {},
   "source": [
    "### Run evaluation doesn't work - trying to debug why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b282a4a-e82a-4e6d-9ae2-a417f6b5bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymc_marketing\n",
    "# pymc_marketing.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbc9c1-cea1-487a-b2c0-558dd54f6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "\n",
    "# # Reload the deepest dependency first\n",
    "# import pymc_marketing.model_builder\n",
    "# importlib.reload(pymc_marketing.model_builder)\n",
    "\n",
    "# # Reload the module that uses model_builder\n",
    "# import pymc_marketing.mmm\n",
    "# importlib.reload(pymc_marketing.mmm)\n",
    "\n",
    "# # Reload your adapter module\n",
    "# import mmm_eval.adapters.pymc\n",
    "# importlib.reload(mmm_eval.adapters.pymc)\n",
    "\n",
    "# # Now re-import PyMCAdapter from the reloaded module\n",
    "# from mmm_eval.adapters.pymc import PyMCAdapter\n",
    "\n",
    "# # Recreate adapter\n",
    "# adapter = PyMCAdapter(config)\n",
    "\n",
    "# adapter.fit(pymc_dataset.rename(columns={\"quantity\": \"response\"}))\n",
    "# adapter.predict(pymc_dataset.rename(columns={\"quantity\": \"response\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea255ff-a3a7-45aa-8db9-b2496a6bc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymc_dataset.columns\n",
    "\n",
    "                                                               \n",
    "#result = run_evaluation(framework=\"pymc_marketing\", config=config, data=pymc_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179bd74-e13a-422f-b03c-7d905092425e",
   "metadata": {},
   "source": [
    "## Construct Meridian dataset and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5421237-3745-464f-8229-2285263d41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = dp.get_meridian_column_map()\n",
    "col_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b87f9-3c21-4669-aad8-adca33110196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.adapters.schemas import MeridianModelSpecSchema, MeridianSamplePosteriorSchema, MeridianInputDataBuilderSchema\n",
    "from meridian import constants\n",
    "import tensorflow_probability as tfp\n",
    "from meridian.model import prior_distribution\n",
    "\n",
    "roi_mu = 0.2     # Mu for ROI prior for each media channel.\n",
    "roi_sigma = 0.9  # Sigma for ROI prior for each media channel.\n",
    "prior = prior_distribution.PriorDistribution(\n",
    "    roi_m=tfp.distributions.LogNormal(roi_mu, roi_sigma, name=constants.ROI_M)\n",
    ")\n",
    "\n",
    "# set up Meridian configs\n",
    "model_spec_config = MeridianModelSpecSchema(prior=prior)\n",
    "sample_posterior_config = MeridianSamplePosteriorSchema(n_chains=4, n_adapt=200, n_burnin=200, n_keep=400)\n",
    "idb_config = MeridianInputDataBuilderSchema(date_column=\"date\", media_channels=col_map[\"media_channels\"],\n",
    "                                            channel_spend_columns=col_map[\"media_channels\"],\n",
    "                                            non_media_treatment_columns=col_map.get(\"non_media_treatment_columns\"),\n",
    "                                            control_columns=col_map.get(\"control_columns\"),\n",
    "                                            response_column=\"quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0187ce-dc8c-4347-aeaa-07f821c53df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmm_eval.configs.configs import MeridianConfig\n",
    "\n",
    "meridian_config = MeridianConfig(input_data_builder_config=idb_config, model_spec_config=model_spec_config,\n",
    "                                 sample_posterior_config=sample_posterior_config, response_column=\"quantity\",\n",
    "                                 revenue_column=\"revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09522cc-822e-4dcd-be79-22c470730dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meridian_dataset = dp.get_meridian_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b8777-d2ae-4863-b9d1-1ddd1576794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_evaluation(framework=\"meridian\", config=meridian_config, data=meridian_dataset,\n",
    "                        test_names=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061f580-66b6-4b36-b69c-290873e38cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3dd644-ab63-46f4-9ea0-650685eec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meridian_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aff5a02-a8e6-4e8a-9783-255e93c87a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'storage' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33mgs://mtx-art-prd-core-model-internal-tool-configs/vertex_model_compatibility_table.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Initialize client\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'storage' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8daa7eeb-8728-44ce-9d3c-b7ae7be98a12",
   "metadata": {},
   "source": [
    "## Hypothesis: Meridian is somehow using revenue as the response column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
